<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Kathleen Finlinson - AI Research and Ethics">
    <title>Kathleen Finlinson</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            font-size: 16px;
            padding: 0 10px;
            margin: 50px auto;
            max-width: 650px;
            color: #333;
        }
        h1, h2 {
            color: #222;
        }
        a {
            color: #0066cc;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>
    <h1>Kathleen Finlinson</h1>
    
    <h2>About Me</h2>
    <p>
        I'm an AI safety researcher and strategist.
        I am working to make deals with misaligned AIs, as well as exploring ways to accelerate AI tools for existential security.
        My background spans applied mathematics, data science, and AI forecasting, 
        which I now apply to critical questions about the development of powerful AI systems.
    </p>

    <h2>Professional Experience</h2>
    <ul>
        <li>Program Manager, Future of Life Foundation <a href="https://www.flf.org/fellowship">Fellowship on AI for Human Reasoning</a> (Jul 2025 - Oct 2025)</li>
        <li>Co-founder, <a href="https://eleosai.org/">Eleos AI Research</a> (Oct 2024 - May 2025)</li>
        <li>Strategy Advisor for AI policymakers (2024): Conducted scenario analysis and long-term forecasting to inform strategic priorities in AI governance</li>
        <li>Research Analyst, Open Philanthropy Project (2018-2019): Focused on AI forecasting</li>
        <li>Data Scientist and Product Manager, various tech companies (2010-2021): Applied machine learning to computer vision, cybersecurity, financial prediction, paleoclimatology, and cancer genomics</li>
        <li><a href="https://www.finlinsonexecutivecoaching.com/">Executive Coach</a> for mission-driven leaders (2021-present)</li>
    </ul>

    <!-- 
    <h2>Research Interests</h2>
    <p>
        At Eleos, my work centers on the study of artificial sentience and long-term AI impacts. I'm interested in navigating the development of AI systems that are not only powerful and capable, but could also be objects of moral concern in their own right.
    </p>
    -->

    <h2>Education and Background</h2>
    <p>
        I hold a Master's in Applied Mathematics from the University of Colorado, Boulder, and degrees 
        in Mathematics and Piano Performance from Brigham Young University. My journey in AI began with an
        interest in AI risk and alignment, which led me to pursue AI safety research and work at Open Philanthropy.
    </p>
    <p>
        Beyond my technical work, I've spent significant time exploring mindfulness and meditation, 
        including living in a Zen monastery for 6 months. This experience informs my approach to 
        understanding the wellbeing of digital minds.
    </p>

    <h2>Connect</h2>
    <p>
        If you're interested in discussing making deals with misaligned AIs or building AI tools to accelerate existential security, feel free to reach out: <a href="mailto:kathleen@finlinson.net">kathleen@finlinson.net</a>
    </p>
    <p>
        For a list of my academic publications, visit my <a href="https://scholar.google.com/citations?hl=en&user=K-sI334AAAAJ">Google Scholar page</a>.
    </p>

</body>
</html>
